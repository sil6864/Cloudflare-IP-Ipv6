# -*- coding: utf-8 -*-
"""
Cloudflare IP æŠ“å–ä¸»ç¨‹åº
--------------------------------
- ä» config.yaml è¯»å–é…ç½®
- å¹¶å‘æŠ“å–å¤šä¸ªæ•°æ®æº
- æ•´åˆç»“æœå¹¶ä¿å­˜
- æ”¯æŒé™æ€/åŠ¨æ€é¡µé¢æŠ“å–
- æ”¯æŒIPå»é‡ã€æ’åºã€åœ°åŒºè¿‡æ»¤ã€æ’é™¤ç­‰åŠŸèƒ½
"""

import os
import asyncio
import logging
import time
from typing import List, Dict, Any, Set, Callable

from ip_utils import (
    load_config, setup_logging, get_retry_session, extract_ips_from_html,
    fetch_ip_static_async, fetch_ip_dynamic, limit_ips, build_ip_exclude_checker,
    filter_ips_by_region, save_ips, send_telegram_notification
)
from playwright.sync_api import sync_playwright, Page

# ===== ä¸»æµç¨‹ =====
async def async_static_crawl(sources: List[Dict[str, Any]], pattern: str, timeout: int, max_ips: int = 0, limit_mode: str = 'random') -> tuple[Dict[str, List[str]], List[str]]:
    """
    å¹¶å‘æŠ“å–æ‰€æœ‰é™æ€é¡µé¢ï¼Œè¿”å›æ¯ä¸ªURLçš„IPåˆ—è¡¨å’Œéœ€è¦JSåŠ¨æ€æŠ“å–çš„URLã€‚
    :param sources: [{url, selector}]åˆ—è¡¨
    :param pattern: IPæ­£åˆ™
    :param timeout: è¶…æ—¶æ—¶é—´
    :param max_ips: æ¯ä¸ªURLæœ€å¤šä¿ç•™çš„IPæ•°é‡ï¼Œ0è¡¨ç¤ºä¸é™åˆ¶
    :param limit_mode: é™åˆ¶æ¨¡å¼ï¼Œ'random'ä¸ºéšæœºä¿ç•™ï¼Œ'top'ä¸ºä¿ç•™é¡µé¢é å‰çš„
    :return: (æ¯ä¸ªURLçš„IPåˆ—è¡¨å­—å…¸, éœ€è¦JSåŠ¨æ€æŠ“å–çš„URLåˆ—è¡¨)
    """
    url_ips_dict: Dict[str, List[str]] = {}
    need_js_urls: List[str] = []
    connector = aiohttp.TCPConnector(ssl=False)
    async with aiohttp.ClientSession(connector=connector) as session:
        tasks = [fetch_ip_static_async(item['url'], pattern, timeout, session, item.get('selector')) for item in sources]
        results = await asyncio.gather(*tasks)
        for url, fetched_ip_list, success in results:
            if success:
                processed_ips_list: List[str]
                if max_ips > 0 and len(fetched_ip_list) > max_ips:
                    original_count = len(fetched_ip_list)
                    processed_ips_list = limit_ips(fetched_ip_list, max_ips, limit_mode)
                    logging.info(f"[LIMIT] URL {url} IPæ•°é‡ä» {original_count} é™åˆ¶ä¸º {len(processed_ips_list)}")
                else:
                    processed_ips_list = fetched_ip_list
                url_ips_dict[url] = processed_ips_list
            else:
                need_js_urls.append(url)
    return url_ips_dict, need_js_urls

def main() -> None:
    """
    ä¸»ç¨‹åºå…¥å£ï¼Œåªä» config.yaml è¯»å–é…ç½®ï¼Œç¼ºå¤±é¡¹æŠ¥é”™ã€‚
    1. è¯»å–é…ç½®å¹¶æ ¡éªŒ
    2. å¼‚æ­¥å¹¶å‘é™æ€æŠ“å–
    3. Playwright åŠ¨æ€æŠ“å–ï¼ˆå¸¦é‡è¯•ï¼‰
    4. ç»“æœå»é‡å¹¶ä¿å­˜
    """
    try:
        config = load_config()
    except Exception as e:
        logging.error(f"é…ç½®åŠ è½½å¤±è´¥: {e}")
        return
    
    sources = config['sources']
    pattern = config['pattern']
    output = config['output']
    timeout = config['timeout']
    log_file = config['log']
    max_workers = config['max_workers']
    log_level = config['log_level']
    js_retry = config['js_retry']
    js_retry_interval = config['js_retry_interval']
    max_ips_per_url = config['max_ips_per_url']
    per_url_limit_mode = config['per_url_limit_mode']
    exclude_ips_config = config['exclude_ips']
    allowed_regions = config['allowed_regions']
    ip_geo_api = config['ip_geo_api']
    auto_detect = config.get('auto_detect', True)
    follow_redirects = config.get('follow_redirects', True)
    enable_telegram_notification = config.get('enable_telegram_notification', False)

    setup_logging(log_file, log_level)
    logging.info(f"å¼€å§‹æ‰§è¡ŒCloudflare IPv6æŠ“å–ï¼Œè‡ªåŠ¨æ£€æµ‹: {auto_detect}")
    
    if os.path.exists(output):
        try:
            os.remove(output)
        except Exception as e:
            logging.error(f"æ— æ³•åˆ é™¤æ—§çš„è¾“å‡ºæ–‡ä»¶: {output}ï¼Œé”™è¯¯: {e}")

    url_ips_map: Dict[str, List[str]] = {}
    static_sources = []
    dynamic_sources = []
    
    # æ ¹æ®é¡µé¢ç±»å‹åˆ†ç±»æ•°æ®æº
    for source in sources:
        url = source['url']
        page_type = source.get('page_type')
        if page_type == 'dynamic' or source.get('actions'):
            dynamic_sources.append(source)
            logging.info(f"URL {url} å·²å½’ç±»ä¸ºåŠ¨æ€æŠ“å–")
        else:
            static_sources.append(source)
            logging.info(f"URL {url} å·²å½’ç±»ä¸ºé™æ€æŠ“å–ï¼ˆå¯èƒ½é™çº§ä¸ºåŠ¨æ€ï¼‰")
    
    # åˆ›å»ºå…¨å±€sessionï¼ˆæ”¯æŒé‡å®šå‘ï¼‰
    session = get_retry_session(timeout)
    if follow_redirects:
        session.max_redirects = 5
    
    # å¤„ç†é™æ€æŠ“å–
    loop = asyncio.get_event_loop()
    url_ips_dict, need_js_urls = loop.run_until_complete(
        async_static_crawl(static_sources, pattern, timeout, max_ips_per_url, per_url_limit_mode)
    )
    url_ips_map.update(url_ips_dict)
    
    # å°†é™æ€æŠ“å–å¤±è´¥çš„URLåŠ å…¥åŠ¨æ€æŠ“å–é˜Ÿåˆ—
    for url in need_js_urls:
        dynamic_sources.append(next(item for item in static_sources if item['url'] == url))
    
    # å¤„ç†åŠ¨æ€æŠ“å–
    if dynamic_sources:
        with sync_playwright() as playwright:
            browser = playwright.chromium.launch(headless=True)
            context = browser.new_context()
            page = context.new_page()
            for source in dynamic_sources:
                url = source['url']
                selector = source.get('selector')
                extracted_ips = fetch_ip_dynamic(url, pattern, timeout, page, selector, js_retry, js_retry_interval)
                if max_ips_per_url > 0 and len(extracted_ips) > max_ips_per_url:
                    original_count = len(extracted_ips)
                    processed_ips = limit_ips(extracted_ips, max_ips_per_url, per_url_limit_mode)
                    logging.info(f"[LIMIT] URL {url} IPæ•°é‡ä» {original_count} é™åˆ¶ä¸º {len(processed_ips)}")
                    url_ips_map[url] = processed_ips
                else:
                    url_ips_map[url] = extracted_ips
            page.close()
            context.close()
            browser.close()
    
    # æ’é™¤IPå’Œåœ°åŒºè¿‡æ»¤
    is_excluded_func = build_ip_exclude_checker(exclude_ips_config)
    excluded_count = 0

    merged_ips = []
    for url, ips_list_for_url in url_ips_map.items():
        original_count_before_exclude = len(ips_list_for_url)
        retained_ips = [ip for ip in ips_list_for_url if not is_excluded_func(ip)]
        excluded_in_source = original_count_before_exclude - len(retained_ips)
        if excluded_in_source > 0:
            logging.info(f"[EXCLUDE] URL {url} æ’é™¤äº† {excluded_in_source} ä¸ªIPï¼Œä¿ç•™ {len(retained_ips)} ä¸ªIP")
        excluded_count += excluded_in_source
        logging.info(f"URL {url} è´¡çŒ®äº† {len(retained_ips)} ä¸ªIP")
        merged_ips.extend(retained_ips)

    final_all_ips = list(dict.fromkeys(merged_ips))

    if allowed_regions and ip_geo_api:
        before_region_count = len(final_all_ips)
        final_all_ips = filter_ips_by_region(final_all_ips, allowed_regions, ip_geo_api)
        after_region_count = len(final_all_ips)
        logging.info(f"[REGION] åœ°åŒºè¿‡æ»¤åï¼ŒIPæ•°é‡ä» {before_region_count} é™è‡³ {after_region_count}")

    save_ips(final_all_ips, output)
    logging.info(f"æœ€ç»ˆåˆå¹¶äº† {len(url_ips_map)} ä¸ªURLçš„IPï¼Œæ’é™¤äº† {excluded_count} ä¸ªIPï¼Œå…± {len(final_all_ips)} ä¸ªå”¯ä¸€IP")

    if enable_telegram_notification:
        telegram_bot_token = os.getenv('TELEGRAM_BOT_TOKEN')
        telegram_chat_id = os.getenv('TELEGRAM_CHAT_ID')
        if telegram_bot_token and telegram_chat_id:
            message = (
                f"âœ… Cloudflare IPv6ä¼˜é€‰IPæŠ“å–å®Œæˆï¼\n\n"
                f"ğŸ“Š **IPæ•°é‡**: {len(final_all_ips)} ä¸ª\n"
                f"ğŸ—‘ï¸ **æ’é™¤IP**: {excluded_count} ä¸ª\n"
                f"ğŸ’¾ **ä¿å­˜è‡³**: `{output}`\n"
            )
            send_telegram_notification(message, telegram_bot_token, telegram_chat_id)
        else:
            logging.warning("Telegramé€šçŸ¥å·²å¯ç”¨ï¼Œä½†æœªæ‰¾åˆ° TELEGRAM_BOT_TOKEN æˆ– TELEGRAM_CHAT_ID ç¯å¢ƒå˜é‡ã€‚è¯·æ£€æŸ¥GitHub Secretsé…ç½®ã€‚")
    else:
        logging.info("Telegramé€šçŸ¥æœªå¯ç”¨ã€‚")

if __name__ == '__main__':
    main()
